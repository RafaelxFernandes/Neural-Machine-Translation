{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.2.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (3.0.6)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (2.4.2)\n",
      "\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (1.22.3)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (1.0.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (3.0.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (0.9.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (0.7.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (0.6.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (8.0.15)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (4.63.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (2.27.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (58.1.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (4.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->spacy) (2.1.0)\n",
      "Requirement already satisfied: torchtext in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: torch==1.8.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from torchtext) (1.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchtext) (2.27.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchtext) (4.63.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchtext) (1.22.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch==1.8.0->torchtext) (4.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchtext) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchtext) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchtext) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchtext) (1.26.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm->torchtext) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.8.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (1.8.0)\n",
      "Requirement already satisfied: torchtext==0.9.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch==1.8.0) (1.22.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch==1.8.0) (4.1.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchtext==0.9.0) (4.63.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchtext==0.9.0) (2.27.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchtext==0.9.0) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchtext==0.9.0) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchtext==0.9.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchtext==0.9.0) (2021.10.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm->torchtext==0.9.0) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install spacy --user\n",
    "%pip install torchtext --user\n",
    "%pip install -U torch==1.8.0 torchtext==0.9.0\n",
    "%pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-lg==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.2.0/en_core_web_lg-3.2.0-py3-none-any.whl (777.4 MB)\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from en-core-web-lg==3.2.0) (3.2.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.9.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (8.0.15)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (4.63.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (21.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.22.3)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.27.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.9)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (58.1.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.7.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (4.1.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.1.0)\n",
      "✔ Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting de-core-news-lg==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_lg-3.2.0/de_core_news_lg-3.2.0-py3-none-any.whl (572.3 MB)\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from de-core-news-lg==3.2.0) (3.2.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (1.22.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (4.63.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (8.0.15)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (3.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (0.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (3.0.9)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (2.27.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (58.1.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (3.0.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (4.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (2.1.0)\n",
      "✔ Download and installation successful\n",
      "You can now load the package via spacy.load('de_core_news_lg')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_lg\n",
    "!python -m spacy download de_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import itertools, os, time , datetime\n",
    "import numpy as np\n",
    "import spacy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.legacy import data, datasets\n",
    "from torchtext.vocab import Vectors, GloVe\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "nltk.download('punkt')\n",
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n",
      "The `device` argument should be set by using `torch.device` or passing a string as an argument. This behavior will be deprecated soon and currently defaults to cpu.\n"
     ]
    }
   ],
   "source": [
    "def preprocess(vocab_size=0, batchsize=16, max_sent_len=20):\n",
    "    '''Loads data from text files into iterators'''\n",
    "\n",
    "    # Load text tokenizers\n",
    "    spacy_de = spacy.load('de_core_news_lg')\n",
    "    spacy_en = spacy.load('en_core_web_lg')\n",
    "\n",
    "    def tokenize(text, lang='en'):\n",
    "        if lang == 'de':\n",
    "            return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "        elif lang == 'en':\n",
    "            return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "        else:\n",
    "            raise Exception('Invalid language')\n",
    "\n",
    "    # Add beginning-of-sentence and end-of-sentence tokens \n",
    "    BOS_WORD = '<s>'\n",
    "    EOS_WORD = '</s>'\n",
    "    DE = data.Field(tokenize=lambda x: tokenize(x, 'de'))\n",
    "    EN = data.Field(tokenize=tokenize, init_token=BOS_WORD, eos_token=EOS_WORD)\n",
    "\n",
    "    # Create sentence pair dataset with max length 20\n",
    "    train, val, test = datasets.Multi30k.splits(exts=('.de', '.en'), fields=(DE, EN), filter_pred = lambda x: max(len(vars(x)['src']), len(vars(x)['trg'])) <= max_sent_len)\n",
    "\n",
    "    # Build vocabulary and convert text to indices\n",
    "    # Convert words that appear fewer than 5 times to <unk>\n",
    "    if vocab_size > 0:\n",
    "        DE.build_vocab(train.src, min_freq=5, max_size=vocab_size)\n",
    "        EN.build_vocab(train.trg, min_freq=5, max_size=vocab_size)\n",
    "    else:\n",
    "        DE.build_vocab(train.src, min_freq=5)\n",
    "        EN.build_vocab(train.trg, min_freq=5)\n",
    "\n",
    "    # Create iterators to process text in batches of approx. the same length\n",
    "    train_iter = data.BucketIterator(train, batch_size=batchsize, device=-1, repeat=False, sort_key=lambda x: len(x.src))\n",
    "    val_iter = data.BucketIterator(val, batch_size=1, device=-1, repeat=False, sort_key=lambda x: len(x.src))\n",
    "    \n",
    "    return DE, EN, train_iter, val_iter\n",
    "\n",
    "# Test\n",
    "timer = time.time()\n",
    "SRC, TGT, train_iter, val_iter = preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test of our preprocessing function. It took 9.5 seconds to load the data. \n",
      "Our German vocab has size 3327 and our English vocab has size 3124.\n",
      "Our training data has 1690 batches, each with 16 sentences, and our validation data has 948 batches.\n"
     ]
    }
   ],
   "source": [
    "print('''This is a test of our preprocessing function. It took {:.1f} seconds to load the data. \n",
    "Our German vocab has size {} and our English vocab has size {}.\n",
    "Our training data has {} batches, each with {} sentences, and our validation data has {} batches.'''.format(\n",
    "time.time() - timer, len(SRC.vocab), len(TGT.vocab), len(train_iter), train_iter.batch_size, len(val_iter)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, embedding, h_dim, num_layers, dropout_p=0.0, bidirectional=True):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.vocab_size, self.embedding_size = embedding.size()\n",
    "        self.num_layers, self.h_dim, self.dropout_p, self.bidirectional = num_layers, h_dim, dropout_p, bidirectional \n",
    "\n",
    "        # Create embedding and LSTM\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_size)\n",
    "        self.embedding.weight.data.copy_(embedding)\n",
    "        self.lstm = nn.LSTM(self.embedding_size, self.h_dim, self.num_layers, dropout=self.dropout_p, bidirectional=bidirectional)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Embed text, get initial LSTM hidden state, and encode with LSTM'''\n",
    "        x = self.dropout(self.embedding(x)) # embedding\n",
    "        h0 = self.init_hidden(x.size(1)) # initial state of LSTM\n",
    "        memory_bank, h = self.lstm(x, h0) # encoding\n",
    "        return memory_bank, h\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        '''Create initial hidden state of zeros: 2-tuple of num_layers x batch size x hidden dim'''\n",
    "        num_layers = self.num_layers * 2 if self.bidirectional else self.num_layers\n",
    "        init = torch.zeros(num_layers, batch_size, self.h_dim)\n",
    "        init = init.cuda() if use_gpu else init\n",
    "        h0 = (init, init.clone())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, pad_token=1, bidirectional=True, h_dim=300):\n",
    "        super(Attention, self).__init__()\n",
    "        self.bidirectional, self.h_dim, self.pad_token = bidirectional, h_dim, pad_token\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, in_e, out_e, out_d):\n",
    "        '''Produces context with attention distribution'''\n",
    "\n",
    "        # Deal with bidirectional encoder, move batches first\n",
    "        if self.bidirectional: # sum hidden states for both directions\n",
    "            out_e = out_e.contiguous().view(out_e.size(0), out_e.size(1), 2, -1).sum(2).view(out_e.size(0), out_e.size(1), -1)\n",
    "            \n",
    "        # Move batches first\n",
    "        out_e = out_e.transpose(0,1) # b x sl x hd\n",
    "        out_d = out_d.transpose(0,1) # b x tl x hd\n",
    "\n",
    "        # Dot product attention, softmax, and reshape\n",
    "        attn = out_e.bmm(out_d.transpose(1,2)) # (b x sl x hd) (b x hd x tl) --> (b x sl x tl)\n",
    "        attn = self.softmax(attn).transpose(1,2) # --> b x tl x sl\n",
    "\n",
    "        # Get attention distribution\n",
    "        context = attn.bmm(out_e) # --> b x tl x hd\n",
    "        context = context.transpose(0,1) # --> tl x b x hd\n",
    "        return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "    def __init__(self, embedding, h_dim, num_layers, dropout_p=0.0):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.vocab_size, self.embedding_size = embedding.size()\n",
    "        self.num_layers, self.h_dim, self.dropout_p = num_layers, h_dim, dropout_p\n",
    "        \n",
    "        # Create embedding and LSTM\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_size)\n",
    "        self.embedding.weight.data.copy_(embedding) \n",
    "        self.lstm = nn.LSTM(self.embedding_size, self.h_dim, self.num_layers, dropout=self.dropout_p)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "    \n",
    "    def forward(self, x, h0):\n",
    "        '''Embed text and pass through LSTM'''\n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        out, h = self.lstm(x, h0)\n",
    "        return out, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq(nn.Module):\n",
    "    def __init__(self, embedding_src, embedding_tgt, h_dim, num_layers, dropout_p, bi, tokens_bos_eos_pad_unk=[0,1,2,3]):\n",
    "        super(Seq2seq, self).__init__()\n",
    "        # Store hyperparameters\n",
    "        self.h_dim = h_dim\n",
    "        self.vocab_size_tgt, self.emb_dim_tgt = embedding_tgt.size()\n",
    "        self.bos_token, self.eos_token, self.pad_token, self.unk_token = tokens_bos_eos_pad_unk\n",
    "\n",
    "        # Create encoder, decoder, attention\n",
    "        self.encoder = EncoderLSTM(embedding_src, h_dim, num_layers, dropout_p=dropout_p, bidirectional=bi)\n",
    "        self.decoder = DecoderLSTM(embedding_tgt, h_dim, num_layers * 2 if bi else num_layers, dropout_p=dropout_p)\n",
    "        self.attention = Attention(pad_token=self.pad_token, bidirectional=bi, h_dim=self.h_dim)\n",
    "\n",
    "        # Create linear layers to combine context and hidden state\n",
    "        self.linear1 = nn.Linear(2 * self.h_dim, self.emb_dim_tgt)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.linear2 = nn.Linear(self.emb_dim_tgt, self.vocab_size_tgt)\n",
    "        \n",
    "        # Share weights between decoder embedding and output \n",
    "        if self.decoder.embedding.weight.size() == self.linear2.weight.size():\n",
    "            self.linear2.weight = self.decoder.embedding.weight\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        if use_gpu: src = src.cuda()\n",
    "        \n",
    "        # Encode\n",
    "        out_e, final_e = self.encoder(src)\n",
    "        \n",
    "        # Decode\n",
    "        out_d, final_d = self.decoder(tgt, final_e)\n",
    "        \n",
    "        # Attend\n",
    "        context = self.attention(src, out_e, out_d)\n",
    "        out_cat = torch.cat((out_d, context), dim=2) \n",
    "        \n",
    "        # Predict (returns probabilities)\n",
    "        x = self.linear1(out_cat)\n",
    "        x = self.dropout(self.tanh(x))\n",
    "        x = self.linear2(x)\n",
    "        return x\n",
    "\n",
    "    def predict(self, src, beam_size=1): \n",
    "        '''Predict top 1 sentence using beam search. Note that beam_size=1 is greedy search.'''\n",
    "        beam_outputs = self.beam_search(src, beam_size, max_len=30) # returns top beam_size options (as list of tuples)\n",
    "        top1 = beam_outputs[0][1] # a list of word indices (as ints)\n",
    "        return top1\n",
    "\n",
    "    def beam_search(self, src, beam_size, max_len, remove_tokens=[]):\n",
    "        '''Returns top beam_size sentences using beam search. Works only when src has batch size 1.'''\n",
    "        if use_gpu: src = src.cuda()\n",
    "        \n",
    "        # Encode\n",
    "        outputs_e, states = self.encoder(src) # batch size = 1\n",
    "        \n",
    "        # Start with '<s>'\n",
    "        init_lprob = -1e10\n",
    "        init_sent = [self.bos_token]\n",
    "        best_options = [(init_lprob, init_sent, states)] # beam\n",
    "        \n",
    "        # Beam search\n",
    "        k = beam_size # store best k options\n",
    "        for length in range(max_len): # maximum target length\n",
    "            options = [] # candidates \n",
    "            for lprob, sentence, current_state in best_options:\n",
    "                # Prepare last word\n",
    "                last_word = sentence[-1]\n",
    "                if last_word != self.eos_token:\n",
    "                    last_word_input = torch.LongTensor([last_word]).view(1,1)\n",
    "                    if use_gpu: last_word_input = last_word_input.cuda()\n",
    "                    # Decode\n",
    "                    outputs_d, new_state = self.decoder(last_word_input, current_state)\n",
    "                    # Attend\n",
    "                    context = self.attention(src, outputs_e, outputs_d)\n",
    "                    out_cat = torch.cat((outputs_d, context), dim=2)\n",
    "                    x = self.linear1(out_cat)\n",
    "                    x = self.dropout(self.tanh(x))\n",
    "                    x = self.linear2(x)\n",
    "                    x = x.squeeze().data.clone()\n",
    "                    # Block predictions of tokens in remove_tokens\n",
    "                    for t in remove_tokens: x[t] = -10e10\n",
    "                    lprobs = torch.log(x.exp() / x.exp().sum()) # log softmax\n",
    "                    # Add top k candidates to options list for next word\n",
    "                    for index in torch.topk(lprobs, k)[1]: \n",
    "                        option = (float(lprobs[index]) + lprob, sentence + [index], new_state) \n",
    "                        options.append(option)\n",
    "                else: # keep sentences ending in '</s>' as candidates\n",
    "                    options.append((lprob, sentence, current_state))\n",
    "            options.sort(key = lambda x: x[0], reverse=True) # sort by lprob\n",
    "            best_options = options[:k] # place top candidates in beam\n",
    "        best_options.sort(key = lambda x: x[0], reverse=True)\n",
    "        return best_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "  '''A handy class for moving averages''' \n",
    "  def __init__(self):\n",
    "    self.reset()\n",
    "  def reset(self):\n",
    "    self.val, self.avg, self.sum, self.count = 0, 0, 0, 0\n",
    "  def update(self, val, n=1):\n",
    "    self.val = val\n",
    "    self.sum += val * n\n",
    "    self.count += n\n",
    "    self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_path = \"bleu-best-model\"\n",
    "early_stop = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_iter, val_iter, model, criterion, optimizer, num_epochs):  \n",
    "\n",
    "    bleu_best = -1\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Validade model with BLEU\n",
    "        bleu_val = validate(val_iter, model, criterion, SRC, TGT)\n",
    "        print(\"BLEU: \" + str(bleu_val))\n",
    "\n",
    "        if bleu_val > bleu_best:\n",
    "            bleu_best = bleu_val\n",
    "            repeat = 0\n",
    "\n",
    "            print('Saving best model...')\n",
    "            torch.save(model, write_path)\n",
    "        else:\n",
    "            repeat += 1\n",
    "\n",
    "        if repeat == early_stop:\n",
    "            break\n",
    "      \n",
    "        # Validate model\n",
    "        with torch.no_grad():\n",
    "          val_loss = validate_losses(val_iter, model, criterion) \n",
    "          print('Validating Epoch [{e}/{num_e}]\\t Average loss: {l:.3f}\\t Perplexity: {p:.3f}'.format(\n",
    "            e=epoch, num_e=num_epochs, l=val_loss, p=torch.FloatTensor([val_loss]).exp().item()))\n",
    "\n",
    "        # Train model\n",
    "        model.train()\n",
    "        losses = AverageMeter()\n",
    "        for i, batch in enumerate(train_iter): \n",
    "            src = batch.src.cuda() if use_gpu else batch.src\n",
    "            tgt = batch.trg.cuda() if use_gpu else batch.trg\n",
    "            \n",
    "            # Forward, backprop, optimizer\n",
    "            model.zero_grad()\n",
    "            scores = model(src, tgt)\n",
    "\n",
    "            # Remove <s> from target and </s> from scores (output)\n",
    "            scores = scores[:-1]\n",
    "            tgt = tgt[1:]           \n",
    "\n",
    "            # Reshape for loss function\n",
    "            scores = scores.view(scores.size(0) * scores.size(1), scores.size(2))\n",
    "            tgt = tgt.view(scores.size(0))\n",
    "\n",
    "            # Pass through loss function\n",
    "            loss = criterion(scores, tgt) \n",
    "            loss.backward()\n",
    "            losses.update(loss.item())\n",
    "\n",
    "            # Clip gradient norms and step optimizer\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Log within epoch\n",
    "            if i % 1000 == 10:\n",
    "                print('''Epoch [{e}/{num_e}]\\t Batch [{b}/{num_b}]\\t Loss: {l:.3f}'''.format(e=epoch+1, num_e=num_epochs, b=i, num_b=len(train_iter), l=losses.avg))\n",
    "\n",
    "        # Log after each epoch\n",
    "        print('''Epoch [{e}/{num_e}] complete. Loss: {l:.3f}'''.format(e=epoch+1, num_e=num_epochs, l=losses.avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(val_iter, model, criterion, SRC, TGT):\n",
    "    model.eval()\n",
    "  \n",
    "    # Iterate over words in validation batch. \n",
    "    bleu = AverageMeter()\n",
    "    sents_out = [] # list of sentences from decoder\n",
    "    sents_ref = [] # list of target sentences \n",
    "    for i, batch in enumerate(val_iter):\n",
    "        # Use GPU\n",
    "        src = batch.src.cuda() if use_gpu else batch.src\n",
    "        trg = batch.trg.cuda() if use_gpu else batch.trg\n",
    "        # Get model prediction (from beam search)\n",
    "        out = model.predict(src, beam_size=1) # list of ints (word indices) from greedy search\n",
    "        ref = list(trg.data.squeeze())\n",
    "        # Prepare sentence for bleu script\n",
    "        remove_tokens = [TGT.vocab.stoi['<pad>'], TGT.vocab.stoi['<s>'], TGT.vocab.stoi['</s>']] \n",
    "        out = [w for w in out if w not in remove_tokens]\n",
    "        ref = [w for w in ref if w not in remove_tokens]\n",
    "        sent_out = ' '.join(TGT.vocab.itos[j] for j in out)\n",
    "        sent_ref = ' '.join(TGT.vocab.itos[j] for j in ref)\n",
    "        sents_out.append(sent_out)\n",
    "        sents_ref.append(sent_ref)\n",
    "    # Run moses bleu script \n",
    "    bleu = corpus_bleu(sents_out, sents_ref) \n",
    "    # Log information after validation\n",
    "    return bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_losses(val_iter, model, criterion):\n",
    "    '''Calculate losses by teacher forcing on the validation set'''\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    for i, batch in enumerate(val_iter):\n",
    "        src = batch.src.cuda() if use_gpu else batch.src\n",
    "        tgt = batch.trg.cuda() if use_gpu else batch.trg\n",
    "        \n",
    "        # Forward \n",
    "        scores = model(src, tgt)\n",
    "        scores = scores[:-1]\n",
    "        tgt = tgt[1:]           \n",
    "        \n",
    "        # Reshape for loss function\n",
    "        scores = scores.view(scores.size(0) * scores.size(1), scores.size(2))\n",
    "        tgt = tgt.view(scores.size(0))\n",
    "        num_words = (tgt != 0).float().sum()\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(scores, tgt) \n",
    "        losses.update(loss.item())\n",
    "    \n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_text(model, input_sentence, SRC, TGT):\n",
    "    sent_german = input_sentence.split(' ') # sentence --> list of words\n",
    "    sent_indices = [SRC.vocab.stoi[word] if word in SRC.vocab.stoi else SRC.vocab.stoi['<unk>'] for word in sent_german]\n",
    "    sent = torch.LongTensor([sent_indices])\n",
    "    if use_gpu: sent = sent.cuda()\n",
    "    sent = sent.view(-1,1) # reshape to sl x bs\n",
    "    print('German: ' + ' '.join([SRC.vocab.itos[index] for index in sent_indices]))\n",
    "    # Predict five sentences with beam search \n",
    "    pred = model.predict(sent, beam_size=5) # returns list of 5 lists of word indices\n",
    "    out = ' '.join([TGT.vocab.itos[index] for index in pred[1:-1]])\n",
    "    print('English: ' + out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 complete\n",
      "10000 complete\n",
      "20000 complete\n",
      "30000 complete\n",
      "40000 complete\n",
      "50000 complete\n",
      "60000 complete\n",
      "70000 complete\n",
      "80000 complete\n",
      "90000 complete\n",
      "100000 complete\n",
      "110000 complete\n",
      "120000 complete\n",
      "130000 complete\n",
      "140000 complete\n",
      "150000 complete\n",
      "160000 complete\n",
      "170000 complete\n",
      "180000 complete\n",
      "190000 complete\n",
      "200000 complete\n",
      "210000 complete\n",
      "error:  –\n",
      "220000 complete\n",
      "230000 complete\n",
      "240000 complete\n",
      "250000 complete\n",
      "260000 complete\n",
      "270000 complete\n",
      "280000 complete\n",
      "290000 complete\n",
      "300000 complete\n",
      "310000 complete\n",
      "320000 complete\n",
      "330000 complete\n",
      "340000 complete\n",
      "350000 complete\n",
      "360000 complete\n",
      "370000 complete\n",
      "380000 complete\n",
      "390000 complete\n",
      "400000 complete\n",
      "error:  –\n",
      "410000 complete\n",
      "420000 complete\n",
      "430000 complete\n",
      "440000 complete\n",
      "450000 complete\n",
      "460000 complete\n",
      "470000 complete\n",
      "480000 complete\n",
      "490000 complete\n",
      "500000 complete\n",
      "510000 complete\n",
      "error:  –\n",
      "520000 complete\n",
      "error:  mit\n",
      "error:  was\n",
      "530000 complete\n",
      "error:  ,\n",
      "540000 complete\n",
      "error:  –\n",
      "550000 complete\n",
      "560000 complete\n",
      "570000 complete\n",
      "580000 complete\n",
      "590000 complete\n",
      "600000 complete\n",
      "610000 complete\n",
      "error:  –\n",
      "620000 complete\n",
      "630000 complete\n",
      "error:  –\n",
      "640000 complete\n",
      "650000 complete\n",
      "660000 complete\n",
      "670000 complete\n",
      "680000 complete\n",
      "690000 complete\n",
      "700000 complete\n",
      "error:  –\n",
      "710000 complete\n",
      "720000 complete\n",
      "730000 complete\n",
      "740000 complete\n",
      "750000 complete\n",
      "error:  –\n",
      "760000 complete\n",
      "770000 complete\n",
      "780000 complete\n",
      "790000 complete\n",
      "800000 complete\n",
      "810000 complete\n",
      "820000 complete\n",
      "830000 complete\n",
      "error:  –\n",
      "840000 complete\n",
      "850000 complete\n",
      "error:  –\n",
      "860000 complete\n",
      "870000 complete\n",
      "error:  –\n",
      "880000 complete\n",
      "890000 complete\n",
      "error:  –\n",
      "900000 complete\n",
      "910000 complete\n",
      "920000 complete\n",
      "930000 complete\n",
      "error:  –\n",
      "error:  –\n",
      "error:  –\n",
      "940000 complete\n",
      "950000 complete\n",
      "960000 complete\n",
      "970000 complete\n",
      "980000 complete\n",
      "990000 complete\n",
      "error:  –\n",
      "error:  –\n",
      "1000000 complete\n",
      "error:  –\n",
      "error:  –\n",
      "1010000 complete\n",
      "error:  –\n",
      "1020000 complete\n",
      "1030000 complete\n",
      "error:  der\n",
      "1040000 complete\n",
      "1050000 complete\n",
      "error:  –\n",
      "1060000 complete\n",
      "1070000 complete\n",
      "1080000 complete\n",
      "1090000 complete\n",
      "1100000 complete\n",
      "1110000 complete\n",
      "error:  ,\n",
      "1120000 complete\n",
      "error:  –\n",
      "1130000 complete\n",
      "1140000 complete\n",
      "1150000 complete\n",
      "1160000 complete\n",
      "1170000 complete\n",
      "1180000 complete\n",
      "1190000 complete\n",
      "1200000 complete\n",
      "1210000 complete\n",
      "error:  –\n",
      "1220000 complete\n",
      "1230000 complete\n",
      "error:  –\n",
      "error:  –\n",
      "1240000 complete\n",
      "1250000 complete\n",
      "error:  –\n",
      "1260000 complete\n",
      "1270000 complete\n",
      "1280000 complete\n",
      "1290000 complete\n",
      "1300000 complete\n",
      "1310000 complete\n",
      "1320000 complete\n",
      "1330000 complete\n",
      "1340000 complete\n",
      "1350000 complete\n",
      "1360000 complete\n",
      "1370000 complete\n",
      "1380000 complete\n",
      "1390000 complete\n",
      "1400000 complete\n",
      "1410000 complete\n",
      "error:  –\n",
      "1420000 complete\n",
      "error:  –\n",
      "1430000 complete\n",
      "error:  –\n",
      "1440000 complete\n",
      "1450000 complete\n",
      "1460000 complete\n",
      "1470000 complete\n",
      "error:  –\n",
      "1480000 complete\n",
      "error:  –\n",
      "1490000 complete\n",
      "1500000 complete\n",
      "error:  –\n",
      "error:  –\n",
      "1510000 complete\n",
      "1520000 complete\n",
      "error:  ,\n",
      "1530000 complete\n",
      "error:  –\n",
      "1540000 complete\n",
      "1550000 complete\n",
      "1560000 complete\n",
      "1570000 complete\n",
      "1580000 complete\n",
      "1590000 complete\n",
      "error:  –\n",
      "1600000 complete\n",
      "error:  –\n",
      "1610000 complete\n",
      "1620000 complete\n",
      "error:  –\n",
      "1630000 complete\n",
      "1640000 complete\n",
      "1650000 complete\n",
      "1660000 complete\n",
      "1670000 complete\n",
      "1680000 complete\n",
      "1690000 complete\n",
      "1700000 complete\n",
      "1710000 complete\n",
      "1720000 complete\n",
      "1730000 complete\n",
      "1740000 complete\n",
      "error:  –\n",
      "1750000 complete\n",
      "1760000 complete\n",
      "error:  –\n",
      "1770000 complete\n",
      "1780000 complete\n",
      "1790000 complete\n",
      "error:  –\n",
      "1800000 complete\n",
      "error:  –\n",
      "1810000 complete\n",
      "error:  –\n",
      "1820000 complete\n",
      "1830000 complete\n",
      "error:  –\n",
      "1840000 complete\n",
      "error:  –\n",
      "1850000 complete\n",
      "error:  –\n",
      "1860000 complete\n",
      "1870000 complete\n",
      "1880000 complete\n",
      "1890000 complete\n",
      "1900000 complete\n",
      "error:  –\n",
      "1910000 complete\n",
      "1920000 complete\n",
      "1930000 complete\n",
      "1940000 complete\n",
      "error:  –\n",
      "1950000 complete\n",
      "error:  –\n",
      "1960000 complete\n",
      "1970000 complete\n",
      "error:  –\n",
      "error:  –\n",
      "1980000 complete\n",
      "error:  –\n",
      "1990000 complete\n",
      "2000000 complete\n",
      "2010000 complete\n",
      "2020000 complete\n",
      "error:  –\n",
      "2030000 complete\n",
      "2040000 complete\n",
      "error:  –\n",
      "2050000 complete\n",
      "2060000 complete\n",
      "2070000 complete\n",
      "error:  –\n",
      "2080000 complete\n",
      "error:  –\n",
      "error:  –\n",
      "2090000 complete\n",
      "error:  –\n",
      "error:  –\n",
      "2100000 complete\n",
      "2110000 complete\n",
      "2120000 complete\n",
      "2130000 complete\n",
      "error:  –\n",
      "2140000 complete\n",
      "2150000 complete\n",
      "2160000 complete\n",
      "error:  –\n",
      "2170000 complete\n",
      "2180000 complete\n",
      "error:  –\n",
      "error:  der\n",
      "2190000 complete\n",
      "error:  –\n",
      "2200000 complete\n",
      "error:  –\n",
      "2210000 complete\n",
      "2220000 complete\n",
      "2230000 complete\n",
      "2240000 complete\n",
      "2250000 complete\n",
      "2260000 complete\n",
      "2270000 complete\n",
      "German embedding saved as np file\n",
      "0 complete\n",
      "10000 complete\n",
      "20000 complete\n",
      "30000 complete\n",
      "40000 complete\n",
      "50000 complete\n",
      "60000 complete\n",
      "70000 complete\n",
      "80000 complete\n",
      "90000 complete\n",
      "100000 complete\n",
      "110000 complete\n",
      "120000 complete\n",
      "130000 complete\n",
      "140000 complete\n",
      "150000 complete\n",
      "160000 complete\n",
      "error:  talk\n",
      "170000 complete\n",
      "180000 complete\n",
      "190000 complete\n",
      "200000 complete\n",
      "210000 complete\n",
      "220000 complete\n",
      "230000 complete\n",
      "240000 complete\n",
      "250000 complete\n",
      "260000 complete\n",
      "270000 complete\n",
      "280000 complete\n",
      "290000 complete\n",
      "300000 complete\n",
      "310000 complete\n",
      "320000 complete\n",
      "330000 complete\n",
      "340000 complete\n",
      "350000 complete\n",
      "360000 complete\n",
      "370000 complete\n",
      "380000 complete\n",
      "390000 complete\n",
      "400000 complete\n",
      "410000 complete\n",
      "420000 complete\n",
      "430000 complete\n",
      "440000 complete\n",
      "450000 complete\n",
      "460000 complete\n",
      "470000 complete\n",
      "480000 complete\n",
      "490000 complete\n",
      "500000 complete\n",
      "510000 complete\n",
      "520000 complete\n",
      "530000 complete\n",
      "540000 complete\n",
      "550000 complete\n",
      "560000 complete\n",
      "570000 complete\n",
      "580000 complete\n",
      "590000 complete\n",
      "600000 complete\n",
      "610000 complete\n",
      "620000 complete\n",
      "630000 complete\n",
      "640000 complete\n",
      "error:  talk\n",
      "650000 complete\n",
      "660000 complete\n",
      "670000 complete\n",
      "680000 complete\n",
      "690000 complete\n",
      "700000 complete\n",
      "710000 complete\n",
      "720000 complete\n",
      "730000 complete\n",
      "740000 complete\n",
      "750000 complete\n",
      "760000 complete\n",
      "770000 complete\n",
      "780000 complete\n",
      "790000 complete\n",
      "800000 complete\n",
      "810000 complete\n",
      "820000 complete\n",
      "830000 complete\n",
      "840000 complete\n",
      "850000 complete\n",
      "860000 complete\n",
      "870000 complete\n",
      "880000 complete\n",
      "890000 complete\n",
      "900000 complete\n",
      "910000 complete\n",
      "920000 complete\n",
      "930000 complete\n",
      "940000 complete\n",
      "950000 complete\n",
      "960000 complete\n",
      "970000 complete\n",
      "980000 complete\n",
      "error:  the\n",
      "error:  see\n",
      "990000 complete\n",
      "1000000 complete\n",
      "1010000 complete\n",
      "1020000 complete\n",
      "1030000 complete\n",
      "1040000 complete\n",
      "1050000 complete\n",
      "error:  #\n",
      "1060000 complete\n",
      "1070000 complete\n",
      "1080000 complete\n",
      "1090000 complete\n",
      "1100000 complete\n",
      "1110000 complete\n",
      "1120000 complete\n",
      "1130000 complete\n",
      "1140000 complete\n",
      "1150000 complete\n",
      "1160000 complete\n",
      "error:  book\n",
      "1170000 complete\n",
      "1180000 complete\n",
      "1190000 complete\n",
      "error:  ,\n",
      "1200000 complete\n",
      "1210000 complete\n",
      "1220000 complete\n",
      "1230000 complete\n",
      "1240000 complete\n",
      "1250000 complete\n",
      "error:  the\n",
      "1260000 complete\n",
      "1270000 complete\n",
      "1280000 complete\n",
      "1290000 complete\n",
      "1300000 complete\n",
      "1310000 complete\n",
      "1320000 complete\n",
      "1330000 complete\n",
      "1340000 complete\n",
      "1350000 complete\n",
      "1360000 complete\n",
      "1370000 complete\n",
      "1380000 complete\n",
      "error:  i\n",
      "1390000 complete\n",
      "1400000 complete\n",
      "1410000 complete\n",
      "1420000 complete\n",
      "1430000 complete\n",
      "1440000 complete\n",
      "1450000 complete\n",
      "1460000 complete\n",
      "1470000 complete\n",
      "1480000 complete\n",
      "1490000 complete\n",
      "1500000 complete\n",
      "1510000 complete\n",
      "1520000 complete\n",
      "1530000 complete\n",
      "error:  war\n",
      "1540000 complete\n",
      "1550000 complete\n",
      "1560000 complete\n",
      "1570000 complete\n",
      "1580000 complete\n",
      "1590000 complete\n",
      "1600000 complete\n",
      "error:  i\n",
      "1610000 complete\n",
      "1620000 complete\n",
      "1630000 complete\n",
      "1640000 complete\n",
      "1650000 complete\n",
      "1660000 complete\n",
      "1670000 complete\n",
      "1680000 complete\n",
      "1690000 complete\n",
      "1700000 complete\n",
      "1710000 complete\n",
      "1720000 complete\n",
      "1730000 complete\n",
      "1740000 complete\n",
      "error:  at\n",
      "1750000 complete\n",
      "1760000 complete\n",
      "1770000 complete\n",
      "1780000 complete\n",
      "1790000 complete\n",
      "1800000 complete\n",
      "1810000 complete\n",
      "error:  i\n",
      "1820000 complete\n",
      "1830000 complete\n",
      "error:  ,\n",
      "1840000 complete\n",
      "1850000 complete\n",
      "error:  and\n",
      "error:  machine\n",
      "1860000 complete\n",
      "1870000 complete\n",
      "1880000 complete\n",
      "1890000 complete\n",
      "1900000 complete\n",
      "1910000 complete\n",
      "1920000 complete\n",
      "1930000 complete\n",
      "1940000 complete\n",
      "1950000 complete\n",
      "1960000 complete\n",
      "error:  in\n",
      "1970000 complete\n",
      "1980000 complete\n",
      "1990000 complete\n",
      "2000000 complete\n",
      "2010000 complete\n",
      "error:  book\n",
      "2020000 complete\n",
      "2030000 complete\n",
      "2040000 complete\n",
      "error:  t\n",
      "error:  from\n",
      "2050000 complete\n",
      "error:  the\n",
      "2060000 complete\n",
      "2070000 complete\n",
      "error:  ,\n",
      "2080000 complete\n",
      "2090000 complete\n",
      "2100000 complete\n",
      "2110000 complete\n",
      "error:  ,\n",
      "2120000 complete\n",
      "2130000 complete\n",
      "2140000 complete\n",
      "2150000 complete\n",
      "2160000 complete\n",
      "2170000 complete\n",
      "error:  i\n",
      "2180000 complete\n",
      "2190000 complete\n",
      "2200000 complete\n",
      "2210000 complete\n",
      "error:  a\n",
      "2220000 complete\n",
      "2230000 complete\n",
      "2240000 complete\n",
      "2250000 complete\n",
      "error:  ,\n",
      "2260000 complete\n",
      "2270000 complete\n",
      "2280000 complete\n",
      "2290000 complete\n",
      "2300000 complete\n",
      "2310000 complete\n",
      "2320000 complete\n",
      "2330000 complete\n",
      "2340000 complete\n",
      "error:  for\n",
      "2350000 complete\n",
      "2360000 complete\n",
      "2370000 complete\n",
      "2380000 complete\n",
      "error:  the\n",
      "2390000 complete\n",
      "2400000 complete\n",
      "2410000 complete\n",
      "2420000 complete\n",
      "error:  i\n",
      "2430000 complete\n",
      "2440000 complete\n",
      "2450000 complete\n",
      "2460000 complete\n",
      "2470000 complete\n",
      "2480000 complete\n",
      "2490000 complete\n",
      "2500000 complete\n",
      "error:  the\n",
      "2510000 complete\n",
      "English embedding saved as np file\n",
      "German: (3327, 300) \t English: (3124, 300)\n"
     ]
    }
   ],
   "source": [
    "def load_embeddings(path, TEXT, embedding_dim=300):\n",
    "    \"\"\" Creates a embedding from a file containing words and vector indices separated by spaces. Modified from https://github.com/A-Jacobson/CNN_Sentence_Classification/blob/master/WordVectors.ipynb \"\"\"\n",
    "    with open(path, encoding=\"utf8\") as f:\n",
    "        embeddings = np.zeros((len(TEXT.vocab), embedding_dim))\n",
    "        for i, line in enumerate(f.readlines()):\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            if word in TEXT.vocab.stoi:\n",
    "                index = TEXT.vocab.stoi[word]\n",
    "                try:\n",
    "                    vector = np.array(values[1:], dtype='float32')\n",
    "                except:\n",
    "                    vector = np.array([0] * 300, dtype='float32')\n",
    "                    print('error: ', word)\n",
    "                embeddings[index] = vector\n",
    "            if i % 10000 == 0:\n",
    "                print('{i} complete'.format(i=i))\n",
    "        return embeddings \n",
    "\n",
    "# Save German embeddings\n",
    "emb_de = load_embeddings('Scripts/wiki.de.vec', SRC)\n",
    "np.save('emb-{}-de'.format(str(len(SRC.vocab))), emb_de)\n",
    "print('German embedding saved as np file')\n",
    "\n",
    "# Save English embeddings\n",
    "emb_en = load_embeddings('Scripts/wiki.en.vec', TGT)\n",
    "np.save('emb-{}-en'.format(str(len(TGT.vocab))), emb_en)\n",
    "print('English embedding saved as np file')\n",
    "\n",
    "# Print sizes\n",
    "print('German: {} \\t English: {}'.format(emb_de.shape, emb_en.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_embeddings(SRC, TGT, np_src_file, np_tgt_file):\n",
    "    '''Load English and German embeddings from saved numpy files'''\n",
    "    emb_tr_src = torch.from_numpy(np.load(np_src_file))\n",
    "    emb_tr_tgt = torch.from_numpy(np.load(np_tgt_file))\n",
    "    return emb_tr_src, emb_tr_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_src, embedding_tgt = download_embeddings(SRC, TGT, 'emb-3327-de.npy', 'emb-3124-en.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model \n",
    "tokens = [TGT.vocab.stoi[x] for x in ['<s>', '</s>', '<pad>', '<unk>']]\n",
    "model = Seq2seq(embedding_src, embedding_tgt, 300, 2, 0.3, True, tokens_bos_eos_pad_unk=tokens)\n",
    "model = model.cuda() if use_gpu else model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create weight to mask padding tokens for loss function\n",
    "weight = torch.ones(len(TGT.vocab))\n",
    "weight[TGT.vocab.stoi['<pad>']] = 0\n",
    "weight = weight.cuda() if use_gpu else weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(weight=weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 9.711550950702173e-232\n",
      "Saving best model...\n",
      "Validating Epoch [0/2]\t Average loss: 8.030\t Perplexity: 3073.212\n",
      "Epoch [1/2]\t Batch [10/1690]\t Loss: 6.864\n",
      "Epoch [1/2]\t Batch [1010/1690]\t Loss: 3.115\n",
      "Epoch [1/2] complete. Loss: 2.730\n",
      "BLEU: 1.356215011113552e-231\n",
      "Saving best model...\n",
      "Validating Epoch [1/2]\t Average loss: 1.768\t Perplexity: 5.857\n",
      "Epoch [2/2]\t Batch [10/1690]\t Loss: 1.897\n",
      "Epoch [2/2]\t Batch [1010/1690]\t Loss: 1.859\n",
      "Epoch [2/2] complete. Loss: 1.817\n"
     ]
    }
   ],
   "source": [
    "train(train_iter, val_iter, model, criterion, optimizer, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German: Ich <unk> nur <unk> ich <unk> in den Bergen und ich <unk> die Berge .\n",
      "English: Elderly <unk> <unk> appears to be <unk> in mountains and see the mountains .\n"
     ]
    }
   ],
   "source": [
    "input = \"Ich kenne nur Berge, ich bleibe in den Bergen und ich liebe die Berge .\"\n",
    "predict_from_text(model, input, SRC, TGT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German: <unk> <unk> <unk> sich als <unk> als <unk> .\n",
      "English: <unk> <unk> as <unk> <unk> as they listen as <unk> <unk> .\n"
     ]
    }
   ],
   "source": [
    "input = \"Ihre Bergung erwies sich als komplizierter als gedacht .\" \n",
    "predict_from_text(model, input, SRC, TGT)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
