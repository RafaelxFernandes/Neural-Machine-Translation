{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tradução utilizando Redes Neurais Recorrentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse documento, nós vamos construir um modelo de aprendizado de máquina para traduzir frases em alemão para inglês. Para isso, vamos utilizar a mesma arquitetura do Google: um modelo de rede neural sequência-para-sequência (neural sequence-to-sequence).\n",
    "\n",
    "Para os detalhes das configurações do Google, recomendamos [Wu et al.](https://arxiv.org/abs/1609.08144). Enquanto que para o nosso modelo, nos basearemos em [Bahdanau et al.](https://arxiv.org/abs/1409.0473), um documento que serve como base para o modelo do Google."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visão geral\n",
    "Nosso objetivo é converter uma frase de origem alemã em uma frase em inglês. Para fazer isso, primeiro codificaremos cada palavra da frase em alemão e, em seguida, decodificaremos uma frase em inglês, uma palavra de cada vez. Durante a decodificação, usaremos a atenção para observar as palavras codificadas em inglês à medida que avançamos.\n",
    "\n",
    "Para treinar nosso modelo de tradução, precisamos de muitos pares de frases alemão-inglês traduzidas por tradutores profissionais. Usaremos a coleção Multi30k. Para treinar modelos maiores, os pesquisadores costumam usar os procedimentos do Parlamento Europeu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.2.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (0.6.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (1.22.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (2.4.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (4.63.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (1.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (58.1.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (0.7.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (3.0.3)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (8.0.15)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (2.27.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (4.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->spacy) (2.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchtext in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchtext) (1.22.3)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchtext) (2.27.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchtext) (4.63.0)\n",
      "Requirement already satisfied: torch==1.8.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from torchtext) (1.8.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch==1.8.0->torchtext) (4.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchtext) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchtext) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchtext) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchtext) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm->torchtext) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.8.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (1.8.0)\n",
      "Requirement already satisfied: torchtext==0.9.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch==1.8.0) (4.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch==1.8.0) (1.22.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchtext==0.9.0) (4.63.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchtext==0.9.0) (2.27.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchtext==0.9.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchtext==0.9.0) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchtext==0.9.0) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->torchtext==0.9.0) (1.26.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm->torchtext==0.9.0) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install spacy --user\n",
    "%pip install torchtext --user\n",
    "%pip install -U torch==1.8.0 torchtext==0.9.0\n",
    "%pip install wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-lg==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.2.0/en_core_web_lg-3.2.0-py3-none-any.whl (777.4 MB)\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from en-core-web-lg==3.2.0) (3.2.3)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.7.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (58.1.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (21.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (4.63.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.22.3)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (8.0.15)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.9)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.27.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.0.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (4.1.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (3.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-lg==3.2.0) (2.1.0)\n",
      "✔ Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_lg')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting de-core-news-lg==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_lg-3.2.0/de_core_news_lg-3.2.0-py3-none-any.whl (572.3 MB)\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from de-core-news-lg==3.2.0) (3.2.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (0.9.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (2.27.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (0.7.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (4.63.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (8.0.15)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (3.0.9)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (3.0.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (1.22.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (58.1.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (21.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (3.0.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (4.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (2.0.12)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->spacy<3.3.0,>=3.2.0->de-core-news-lg==3.2.0) (2.1.0)\n",
      "✔ Download and installation successful\n",
      "You can now load the package via spacy.load('de_core_news_lg')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_lg\n",
    "!python -m spacy download de_core_news_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.legacy import data, datasets\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import corpus_bleu\n",
    "nltk.download('punkt')\n",
    "\n",
    "import time \n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hiperparâmetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "# Pre-process\n",
    "BATCH_SIZE = 16\n",
    "MAX_SENT_LEN = 20\n",
    "MIN_FREQ = 5\n",
    "\n",
    "# Encoder e Decoder\n",
    "DROPOUT_P = 0.0\n",
    "\n",
    "# Beam search\n",
    "BEAM_SIZE = 4\n",
    "INIT_LPROB = -1e10\n",
    "\n",
    "# Train\n",
    "write_path = \"bleu-best-model\"\n",
    "EARLY_STOP = 5\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "# Optimizer\n",
    "LEARNING_RATE = 2e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pré-processamento\n",
    "Nós pré-processamos os dados com a biblioteca spacy. No pré-processamento, dividimos nossa frase em tokens (palavras) e adicionamos tokens especiais $<s>$ e $</s>$ para marcar o início e o fim das frases. Também substituímos palavras que ocorrem menos de 5 vezes por um token  $<unk>$ (unknown), pois isso nos ajuda a manter nosso vocabulário em 3.124 palavras em inglês e 3.327 palavras em alemão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    '''\n",
    "    Loads data from text files into iterators\n",
    "    '''\n",
    "\n",
    "    # Load text tokenizers\n",
    "    spacy_de = spacy.load('de_core_news_lg')\n",
    "    spacy_en = spacy.load('en_core_web_lg')\n",
    "\n",
    "    def tokenize(text, lang = 'en'):\n",
    "        if lang == 'de':\n",
    "            return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "        elif lang == 'en':\n",
    "            return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "        else:\n",
    "            raise Exception('Invalid language')\n",
    "\n",
    "    # Add beginning-of-sentence and end-of-sentence tokens \n",
    "    BOS_WORD = '<s>'\n",
    "    EOS_WORD = '</s>'\n",
    "    DE = data.Field(tokenize = lambda x: tokenize(x, 'de'))\n",
    "    EN = data.Field(tokenize = tokenize, init_token = BOS_WORD, eos_token = EOS_WORD)\n",
    "\n",
    "    # Create sentence pair dataset with max length equals to MAX_SENT_LEN\n",
    "    train, val, test = datasets.Multi30k.splits(\n",
    "        exts=('.de', '.en'), \n",
    "        fields = (DE, EN), \n",
    "        filter_pred = lambda x: max(len(vars(x)['src']), len(vars(x)['trg'])) <= MAX_SENT_LEN)\n",
    "\n",
    "    # Build vocabulary and convert text to indices\n",
    "    # Convert words that appear fewer than MIN_FREQ times to <unk>\n",
    "    DE.build_vocab(train.src, min_freq = MIN_FREQ)\n",
    "    EN.build_vocab(train.trg, min_freq = MIN_FREQ)\n",
    "\n",
    "    # Create iterators to process text in batches of approx. the same length\n",
    "    train_iter = data.BucketIterator(\n",
    "        train, \n",
    "        batch_size = BATCH_SIZE,\n",
    "        repeat = False, \n",
    "        sort_key = lambda x: len(x.src)\n",
    "    )\n",
    "    \n",
    "    val_iter = data.BucketIterator(\n",
    "        val, \n",
    "        batch_size = 1,\n",
    "        repeat = False, \n",
    "        sort_key = lambda x: len(x.src)\n",
    "    )\n",
    "    \n",
    "    return DE, EN, train_iter, val_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "timer = time.time()\n",
    "SRC, TGT, train_iter, val_iter = preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test of our preprocessing function. It took 9.4 seconds to load the data. \n",
      "Our German vocab has size 3327 and our English vocab has size 3124.\n",
      "Our training data has 1690 batches, each with 16 sentences, and our validation data has 948 batches.\n"
     ]
    }
   ],
   "source": [
    "print('''This is a test of our preprocessing function. It took {:.1f} seconds to load the data. \n",
    "Our German vocab has size {} and our English vocab has size {}.\n",
    "Our training data has {} batches, each with {} sentences, and our validation data has {} batches.'''.format(\n",
    "time.time() - timer, len(SRC.vocab), len(TGT.vocab), len(train_iter), train_iter.batch_size, len(val_iter)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O Modelo\n",
    "Baseado na plataforma [OpenNMT](https://github.com/OpenNMT/OpenNMT-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(filename = \"Imagens/translation_diagram.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings\n",
    "O primeiro passo para ambos o codificador e decodificador é converter as palavras de entrada em vetores, uma forma com que o nosso modelo possa trabalhar em cima. Fazemos isso utilizando word embeddings, que são mapeamentos de cada palavra no nosso vocabulário para algum espaço de alta dimensão (no nosso caso, 300 dimensões)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(path, TEXT, embedding_dim = 300):\n",
    "    ''' \n",
    "    Creates a embedding from a file containing words and vector indices separated by spaces. \n",
    "    Modified from https://github.com/A-Jacobson/CNN_Sentence_Classification/blob/master/WordVectors.ipynb \n",
    "    '''\n",
    "    \n",
    "    with open(path, encoding = \"utf8\") as f:\n",
    "        embeddings = np.zeros((len(TEXT.vocab), embedding_dim))\n",
    "        \n",
    "        for i, line in enumerate(f.readlines()):\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            \n",
    "            if word in TEXT.vocab.stoi:\n",
    "                index = TEXT.vocab.stoi[word]\n",
    "                \n",
    "                try:\n",
    "                    vector = np.array(values[1:], dtype = 'float32')\n",
    "                except:\n",
    "                    vector = np.array([0] * embedding_dim, dtype = 'float32')\n",
    "                    print('error: ', word)\n",
    "                \n",
    "                embeddings[index] = vector\n",
    "            \n",
    "            if i % 10000 == 0:\n",
    "                print('{i} complete'.format(i=i))\n",
    "        \n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 complete\n",
      "10000 complete\n",
      "20000 complete\n",
      "30000 complete\n",
      "40000 complete\n",
      "50000 complete\n",
      "60000 complete\n",
      "70000 complete\n",
      "80000 complete\n",
      "90000 complete\n",
      "100000 complete\n",
      "110000 complete\n",
      "120000 complete\n",
      "130000 complete\n",
      "140000 complete\n",
      "150000 complete\n",
      "160000 complete\n",
      "170000 complete\n",
      "180000 complete\n",
      "190000 complete\n",
      "200000 complete\n",
      "210000 complete\n",
      "error:  –\n",
      "220000 complete\n",
      "230000 complete\n",
      "240000 complete\n",
      "250000 complete\n",
      "260000 complete\n",
      "270000 complete\n",
      "280000 complete\n",
      "290000 complete\n",
      "300000 complete\n",
      "310000 complete\n",
      "320000 complete\n",
      "330000 complete\n",
      "340000 complete\n",
      "350000 complete\n",
      "360000 complete\n",
      "370000 complete\n",
      "380000 complete\n",
      "390000 complete\n",
      "400000 complete\n",
      "error:  –\n",
      "410000 complete\n",
      "420000 complete\n",
      "430000 complete\n",
      "440000 complete\n",
      "450000 complete\n",
      "460000 complete\n",
      "470000 complete\n",
      "480000 complete\n",
      "490000 complete\n",
      "500000 complete\n",
      "510000 complete\n",
      "error:  –\n",
      "520000 complete\n",
      "error:  mit\n",
      "error:  was\n",
      "530000 complete\n",
      "error:  ,\n",
      "540000 complete\n",
      "error:  –\n",
      "550000 complete\n",
      "560000 complete\n",
      "570000 complete\n",
      "580000 complete\n",
      "590000 complete\n",
      "600000 complete\n",
      "610000 complete\n",
      "error:  –\n",
      "620000 complete\n",
      "630000 complete\n",
      "error:  –\n",
      "640000 complete\n",
      "650000 complete\n",
      "660000 complete\n",
      "670000 complete\n",
      "680000 complete\n",
      "690000 complete\n",
      "700000 complete\n",
      "error:  –\n",
      "710000 complete\n",
      "720000 complete\n",
      "730000 complete\n",
      "740000 complete\n",
      "750000 complete\n",
      "error:  –\n",
      "760000 complete\n",
      "770000 complete\n",
      "780000 complete\n",
      "790000 complete\n",
      "800000 complete\n",
      "810000 complete\n",
      "820000 complete\n",
      "830000 complete\n",
      "error:  –\n",
      "840000 complete\n",
      "850000 complete\n",
      "error:  –\n",
      "860000 complete\n",
      "870000 complete\n",
      "error:  –\n",
      "880000 complete\n",
      "890000 complete\n",
      "error:  –\n",
      "900000 complete\n",
      "910000 complete\n",
      "920000 complete\n",
      "930000 complete\n",
      "error:  –\n",
      "error:  –\n",
      "error:  –\n",
      "940000 complete\n",
      "950000 complete\n",
      "960000 complete\n",
      "970000 complete\n",
      "980000 complete\n",
      "990000 complete\n",
      "error:  –\n",
      "error:  –\n",
      "1000000 complete\n",
      "error:  –\n",
      "error:  –\n",
      "1010000 complete\n",
      "error:  –\n",
      "1020000 complete\n",
      "1030000 complete\n",
      "error:  der\n",
      "1040000 complete\n",
      "1050000 complete\n",
      "error:  –\n",
      "1060000 complete\n",
      "1070000 complete\n",
      "1080000 complete\n",
      "1090000 complete\n",
      "1100000 complete\n",
      "1110000 complete\n",
      "error:  ,\n",
      "1120000 complete\n",
      "error:  –\n",
      "1130000 complete\n",
      "1140000 complete\n",
      "1150000 complete\n",
      "1160000 complete\n",
      "1170000 complete\n",
      "1180000 complete\n",
      "1190000 complete\n",
      "1200000 complete\n",
      "1210000 complete\n",
      "error:  –\n",
      "1220000 complete\n",
      "1230000 complete\n",
      "error:  –\n",
      "error:  –\n",
      "1240000 complete\n",
      "1250000 complete\n",
      "error:  –\n",
      "1260000 complete\n",
      "1270000 complete\n",
      "1280000 complete\n",
      "1290000 complete\n",
      "1300000 complete\n",
      "1310000 complete\n",
      "1320000 complete\n",
      "1330000 complete\n",
      "1340000 complete\n",
      "1350000 complete\n",
      "1360000 complete\n",
      "1370000 complete\n",
      "1380000 complete\n",
      "1390000 complete\n",
      "1400000 complete\n",
      "1410000 complete\n",
      "error:  –\n",
      "1420000 complete\n",
      "error:  –\n",
      "1430000 complete\n",
      "error:  –\n",
      "1440000 complete\n",
      "1450000 complete\n",
      "1460000 complete\n",
      "1470000 complete\n",
      "error:  –\n",
      "1480000 complete\n",
      "error:  –\n",
      "1490000 complete\n",
      "1500000 complete\n",
      "error:  –\n",
      "error:  –\n",
      "1510000 complete\n",
      "1520000 complete\n",
      "error:  ,\n",
      "1530000 complete\n",
      "error:  –\n",
      "1540000 complete\n",
      "1550000 complete\n",
      "1560000 complete\n",
      "1570000 complete\n",
      "1580000 complete\n",
      "1590000 complete\n",
      "error:  –\n",
      "1600000 complete\n",
      "error:  –\n",
      "1610000 complete\n",
      "1620000 complete\n",
      "error:  –\n",
      "1630000 complete\n",
      "1640000 complete\n",
      "1650000 complete\n",
      "1660000 complete\n",
      "1670000 complete\n",
      "1680000 complete\n",
      "1690000 complete\n",
      "1700000 complete\n",
      "1710000 complete\n",
      "1720000 complete\n",
      "1730000 complete\n",
      "1740000 complete\n",
      "error:  –\n",
      "1750000 complete\n",
      "1760000 complete\n",
      "error:  –\n",
      "1770000 complete\n",
      "1780000 complete\n",
      "1790000 complete\n",
      "error:  –\n",
      "1800000 complete\n",
      "error:  –\n",
      "1810000 complete\n",
      "error:  –\n",
      "1820000 complete\n",
      "1830000 complete\n",
      "error:  –\n",
      "1840000 complete\n",
      "error:  –\n",
      "1850000 complete\n",
      "error:  –\n",
      "1860000 complete\n",
      "1870000 complete\n",
      "1880000 complete\n",
      "1890000 complete\n",
      "1900000 complete\n",
      "error:  –\n",
      "1910000 complete\n",
      "1920000 complete\n",
      "1930000 complete\n",
      "1940000 complete\n",
      "error:  –\n",
      "1950000 complete\n",
      "error:  –\n",
      "1960000 complete\n",
      "1970000 complete\n",
      "error:  –\n",
      "error:  –\n",
      "1980000 complete\n",
      "error:  –\n",
      "1990000 complete\n",
      "2000000 complete\n",
      "2010000 complete\n",
      "2020000 complete\n",
      "error:  –\n",
      "2030000 complete\n",
      "2040000 complete\n",
      "error:  –\n",
      "2050000 complete\n",
      "2060000 complete\n",
      "2070000 complete\n",
      "error:  –\n",
      "2080000 complete\n",
      "error:  –\n",
      "error:  –\n",
      "2090000 complete\n",
      "error:  –\n",
      "error:  –\n",
      "2100000 complete\n",
      "2110000 complete\n",
      "2120000 complete\n",
      "2130000 complete\n",
      "error:  –\n",
      "2140000 complete\n",
      "2150000 complete\n",
      "2160000 complete\n",
      "error:  –\n",
      "2170000 complete\n",
      "2180000 complete\n",
      "error:  –\n",
      "error:  der\n",
      "2190000 complete\n",
      "error:  –\n",
      "2200000 complete\n",
      "error:  –\n",
      "2210000 complete\n",
      "2220000 complete\n",
      "2230000 complete\n",
      "2240000 complete\n",
      "2250000 complete\n",
      "2260000 complete\n",
      "2270000 complete\n",
      "German embedding saved as np file\n"
     ]
    }
   ],
   "source": [
    "# Save German embeddings\n",
    "# Source: https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.de.vec\n",
    "emb_de = load_embeddings('Scripts/wiki.de.vec', SRC)\n",
    "np.save('emb-{}-de'.format(str(len(SRC.vocab))), emb_de)\n",
    "print('German embedding saved as np file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 complete\n",
      "10000 complete\n",
      "20000 complete\n",
      "30000 complete\n",
      "40000 complete\n",
      "50000 complete\n",
      "60000 complete\n",
      "70000 complete\n",
      "80000 complete\n",
      "90000 complete\n",
      "100000 complete\n",
      "110000 complete\n",
      "120000 complete\n",
      "130000 complete\n",
      "140000 complete\n",
      "150000 complete\n",
      "160000 complete\n",
      "error:  talk\n",
      "170000 complete\n",
      "180000 complete\n",
      "190000 complete\n",
      "200000 complete\n",
      "210000 complete\n",
      "220000 complete\n",
      "230000 complete\n",
      "240000 complete\n",
      "250000 complete\n",
      "260000 complete\n",
      "270000 complete\n",
      "280000 complete\n",
      "290000 complete\n",
      "300000 complete\n",
      "310000 complete\n",
      "320000 complete\n",
      "330000 complete\n",
      "340000 complete\n",
      "350000 complete\n",
      "360000 complete\n",
      "370000 complete\n",
      "380000 complete\n",
      "390000 complete\n",
      "400000 complete\n",
      "410000 complete\n",
      "420000 complete\n",
      "430000 complete\n",
      "440000 complete\n",
      "450000 complete\n",
      "460000 complete\n",
      "470000 complete\n",
      "480000 complete\n",
      "490000 complete\n",
      "500000 complete\n",
      "510000 complete\n",
      "520000 complete\n",
      "530000 complete\n",
      "540000 complete\n",
      "550000 complete\n",
      "560000 complete\n",
      "570000 complete\n",
      "580000 complete\n",
      "590000 complete\n",
      "600000 complete\n",
      "610000 complete\n",
      "620000 complete\n",
      "630000 complete\n",
      "640000 complete\n",
      "error:  talk\n",
      "650000 complete\n",
      "660000 complete\n",
      "670000 complete\n",
      "680000 complete\n",
      "690000 complete\n",
      "700000 complete\n",
      "710000 complete\n",
      "720000 complete\n",
      "730000 complete\n",
      "740000 complete\n",
      "750000 complete\n",
      "760000 complete\n",
      "770000 complete\n",
      "780000 complete\n",
      "790000 complete\n",
      "800000 complete\n",
      "810000 complete\n",
      "820000 complete\n",
      "830000 complete\n",
      "840000 complete\n",
      "850000 complete\n",
      "860000 complete\n",
      "870000 complete\n",
      "880000 complete\n",
      "890000 complete\n",
      "900000 complete\n",
      "910000 complete\n",
      "920000 complete\n",
      "930000 complete\n",
      "940000 complete\n",
      "950000 complete\n",
      "960000 complete\n",
      "970000 complete\n",
      "980000 complete\n",
      "error:  the\n",
      "error:  see\n",
      "990000 complete\n",
      "1000000 complete\n",
      "1010000 complete\n",
      "1020000 complete\n",
      "1030000 complete\n",
      "1040000 complete\n",
      "1050000 complete\n",
      "error:  #\n",
      "1060000 complete\n",
      "1070000 complete\n",
      "1080000 complete\n",
      "1090000 complete\n",
      "1100000 complete\n",
      "1110000 complete\n",
      "1120000 complete\n",
      "1130000 complete\n",
      "1140000 complete\n",
      "1150000 complete\n",
      "1160000 complete\n",
      "error:  book\n",
      "1170000 complete\n",
      "1180000 complete\n",
      "1190000 complete\n",
      "error:  ,\n",
      "1200000 complete\n",
      "1210000 complete\n",
      "1220000 complete\n",
      "1230000 complete\n",
      "1240000 complete\n",
      "1250000 complete\n",
      "error:  the\n",
      "1260000 complete\n",
      "1270000 complete\n",
      "1280000 complete\n",
      "1290000 complete\n",
      "1300000 complete\n",
      "1310000 complete\n",
      "1320000 complete\n",
      "1330000 complete\n",
      "1340000 complete\n",
      "1350000 complete\n",
      "1360000 complete\n",
      "1370000 complete\n",
      "1380000 complete\n",
      "error:  i\n",
      "1390000 complete\n",
      "1400000 complete\n",
      "1410000 complete\n",
      "1420000 complete\n",
      "1430000 complete\n",
      "1440000 complete\n",
      "1450000 complete\n",
      "1460000 complete\n",
      "1470000 complete\n",
      "1480000 complete\n",
      "1490000 complete\n",
      "1500000 complete\n",
      "1510000 complete\n",
      "1520000 complete\n",
      "1530000 complete\n",
      "error:  war\n",
      "1540000 complete\n",
      "1550000 complete\n",
      "1560000 complete\n",
      "1570000 complete\n",
      "1580000 complete\n",
      "1590000 complete\n",
      "1600000 complete\n",
      "error:  i\n",
      "1610000 complete\n",
      "1620000 complete\n",
      "1630000 complete\n",
      "1640000 complete\n",
      "1650000 complete\n",
      "1660000 complete\n",
      "1670000 complete\n",
      "1680000 complete\n",
      "1690000 complete\n",
      "1700000 complete\n",
      "1710000 complete\n",
      "1720000 complete\n",
      "1730000 complete\n",
      "1740000 complete\n",
      "error:  at\n",
      "1750000 complete\n",
      "1760000 complete\n",
      "1770000 complete\n",
      "1780000 complete\n",
      "1790000 complete\n",
      "1800000 complete\n",
      "1810000 complete\n",
      "error:  i\n",
      "1820000 complete\n",
      "1830000 complete\n",
      "error:  ,\n",
      "1840000 complete\n",
      "1850000 complete\n",
      "error:  and\n",
      "error:  machine\n",
      "1860000 complete\n",
      "1870000 complete\n",
      "1880000 complete\n",
      "1890000 complete\n",
      "1900000 complete\n",
      "1910000 complete\n",
      "1920000 complete\n",
      "1930000 complete\n",
      "1940000 complete\n",
      "1950000 complete\n",
      "1960000 complete\n",
      "error:  in\n",
      "1970000 complete\n",
      "1980000 complete\n",
      "1990000 complete\n",
      "2000000 complete\n",
      "2010000 complete\n",
      "error:  book\n",
      "2020000 complete\n",
      "2030000 complete\n",
      "2040000 complete\n",
      "error:  t\n",
      "error:  from\n",
      "2050000 complete\n",
      "error:  the\n",
      "2060000 complete\n",
      "2070000 complete\n",
      "error:  ,\n",
      "2080000 complete\n",
      "2090000 complete\n",
      "2100000 complete\n",
      "2110000 complete\n",
      "error:  ,\n",
      "2120000 complete\n",
      "2130000 complete\n",
      "2140000 complete\n",
      "2150000 complete\n",
      "2160000 complete\n",
      "2170000 complete\n",
      "error:  i\n",
      "2180000 complete\n",
      "2190000 complete\n",
      "2200000 complete\n",
      "2210000 complete\n",
      "error:  a\n",
      "2220000 complete\n",
      "2230000 complete\n",
      "2240000 complete\n",
      "2250000 complete\n",
      "error:  ,\n",
      "2260000 complete\n",
      "2270000 complete\n",
      "2280000 complete\n",
      "2290000 complete\n",
      "2300000 complete\n",
      "2310000 complete\n",
      "2320000 complete\n",
      "2330000 complete\n",
      "2340000 complete\n",
      "error:  for\n",
      "2350000 complete\n",
      "2360000 complete\n",
      "2370000 complete\n",
      "2380000 complete\n",
      "error:  the\n",
      "2390000 complete\n",
      "2400000 complete\n",
      "2410000 complete\n",
      "2420000 complete\n",
      "error:  i\n",
      "2430000 complete\n",
      "2440000 complete\n",
      "2450000 complete\n",
      "2460000 complete\n",
      "2470000 complete\n",
      "2480000 complete\n",
      "2490000 complete\n",
      "2500000 complete\n",
      "error:  the\n",
      "2510000 complete\n",
      "English embedding saved as np file\n"
     ]
    }
   ],
   "source": [
    "# Save English embeddings\n",
    "# Source: https://dl.fbaipublicfiles.com/fasttext/vectors-wiki/wiki.en.vec\n",
    "emb_en = load_embeddings('Scripts/wiki.en.vec', TGT)\n",
    "np.save('emb-{}-en'.format(str(len(TGT.vocab))), emb_en)\n",
    "print('English embedding saved as np file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German: (3327, 300) \t English: (3124, 300)\n"
     ]
    }
   ],
   "source": [
    "# Print sizes\n",
    "print('German: {} \\t English: {}'.format(emb_de.shape, emb_en.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificador\n",
    "Nosso codificador (vermelho no diagrama do modelo acima) é uma rede neural recorrente bidirecional. \"Bidirecional\" significa simplesmente que rodamos o modelo tanto para frente quanto para trás ao longo da frase.\n",
    "\n",
    "Nosso codificador gera um vetor para cada palavra na frase de origem. Todos esses vetores juntos são chamados de banco de memória (memory bank)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, embedding, h_dim, num_layers, dropout_p, bidirectional = True):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.vocab_size, self.embedding_size = embedding.size()\n",
    "        self.num_layers, self.h_dim, self.dropout_p, self.bidirectional = num_layers, h_dim, dropout_p, bidirectional \n",
    "\n",
    "        # Create embedding and LSTM\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_size)\n",
    "        self.embedding.weight.data.copy_(embedding)\n",
    "        self.lstm = nn.LSTM(self.embedding_size, self.h_dim, self.num_layers, dropout = self.dropout_p, bidirectional = bidirectional)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        Embed text, get initial LSTM hidden state, and encode with LSTM\n",
    "        '''\n",
    "        x = self.dropout(self.embedding(x)) # embedding\n",
    "        h0 = self.init_hidden(x.size(1)) # initial state of LSTM\n",
    "        memory_bank, h = self.lstm(x, h0) # encoding\n",
    "        \n",
    "        return memory_bank, h\n",
    "        \n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        '''\n",
    "        Create initial hidden state of zeros: 2-tuple of num_layers x batch size x hidden dim\n",
    "        '''\n",
    "        num_layers = self.num_layers * 2 if self.bidirectional else self.num_layers\n",
    "        \n",
    "        init = torch.zeros(num_layers, batch_size, self.h_dim)\n",
    "        init = init.cuda() if use_gpu else init\n",
    "        \n",
    "        h0 = (init, init.clone())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decodificador\n",
    "Nosso decodificador (azul e amarelo no diagrama) é uma rede neural recorrente. Dentro do nosso decodificador, temos uma camada de atenção, que analisa o banco de memória do codificador.\n",
    "\n",
    "Começamos alimentando o token inicial $<s>$. Nosso decodificador tenta prever a próxima palavra emitindo uma distribuição sobre todas as palavras do vocabulário. Durante o treinamento, conhecemos a sentença verdadeira, então a colocamos no decodificador palavra por palavra em cada etapa. Penalizamos as previsões do modelo usando uma função de perda de entropia cruzada (cross-entropy loss). Durante o teste, não conhecemos a sentença verdadeira, então usamos uma previsão do modelo como entrada para a próxima etapa de tempo. Discutiremos esse processo com mais detalhes abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "    def __init__(self, embedding, h_dim, num_layers, dropout_p):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.vocab_size, self.embedding_size = embedding.size()\n",
    "        self.num_layers, self.h_dim, self.dropout_p = num_layers, h_dim, dropout_p\n",
    "        \n",
    "        # Create embedding and LSTM\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_size)\n",
    "        self.embedding.weight.data.copy_(embedding) \n",
    "        self.lstm = nn.LSTM(self.embedding_size, self.h_dim, self.num_layers, dropout = self.dropout_p)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        \n",
    "    \n",
    "    def forward(self, x, h0):\n",
    "        '''\n",
    "        Embed text and pass through LSTM\n",
    "        '''\n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        out, h = self.lstm(x, h0)\n",
    "        \n",
    "        return out, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atenção\n",
    "A atenção permite que nosso decodificador veja nossas palavras-fonte codificadas durante a tradução. Usamos a atenção do produto escalar (dot-product attention), o que significa que pegamos o produto escalar da saída do nosso decodificador intermediário e da saída do nosso codificador. Em seguida, tomamos uma soma ponderada de nossos vetores codificadores, usando esse produto escalar como o peso.\n",
    "\n",
    "Existem muitos outros tipos de atenção, descritos com mais detalhes [aqui](https://ruder.io/deep-learning-nlp-best-practices/index.html#attention), mas usamos atenção de produto escalar porque é simples e funciona bem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, pad_token=1, bidirectional = True, h_dim = 300):\n",
    "        super(Attention, self).__init__()\n",
    "        self.bidirectional, self.h_dim, self.pad_token = bidirectional, h_dim, pad_token\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "        \n",
    "\n",
    "    def forward(self, in_e, out_e, out_d):\n",
    "        '''\n",
    "        Produces context with attention distribution\n",
    "        '''\n",
    "        # Deal with bidirectional encoder, move batches first\n",
    "        # Sum hidden states for both directions\n",
    "        if self.bidirectional: \n",
    "            out_e = out_e.contiguous().view(\n",
    "                out_e.size(0), \n",
    "                out_e.size(1), \n",
    "                2, \n",
    "                -1\n",
    "            ).sum(2).view(\n",
    "                out_e.size(0), \n",
    "                out_e.size(1), \n",
    "                -1\n",
    "            )\n",
    "            \n",
    "        # Move batches first\n",
    "        out_e = out_e.transpose(0, 1)\n",
    "        out_d = out_d.transpose(0, 1)\n",
    "\n",
    "        # Dot product attention, softmax, and reshape\n",
    "        attn = out_e.bmm(out_d.transpose(1, 2))\n",
    "        attn = self.softmax(attn).transpose(1, 2)\n",
    "\n",
    "        # Get attention distribution\n",
    "        context = attn.bmm(out_e)\n",
    "        context = context.transpose(0, 1)\n",
    "        \n",
    "        return context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam Search\n",
    "No momento do teste, precisamos usar a saída do nosso decodificador como entrada para o modelo na próxima etapa de tempo. Poderíamos fazer isso pegando a palavra mais provável de cada vez, uma estratégia conhecida como busca gulosa. Aqui, usaremos um método mais sofisticado conhecido como beam search, que mantém em torno de uma lista de sentenças parciais prováveis ​​durante a decodificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo final\n",
    "Nosso modelo final combina o Codificador, Decodificador, Atenção e Beam Search. Chamamos ele de Seq2seq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq(nn.Module):\n",
    "    def __init__(self, embedding_src, embedding_tgt, h_dim, num_layers, dropout_p, bi, tokens_bos_eos_pad_unk = [0,1,2,3]):\n",
    "        super(Seq2seq, self).__init__()\n",
    "\n",
    "        # Store hyperparameters\n",
    "        self.h_dim = h_dim\n",
    "        self.vocab_size_tgt, self.emb_dim_tgt = embedding_tgt.size()\n",
    "        self.bos_token, self.eos_token, self.pad_token, self.unk_token = tokens_bos_eos_pad_unk\n",
    "\n",
    "        # Create encoder, decoder, attention\n",
    "        self.encoder = EncoderLSTM(embedding_src, h_dim, num_layers, dropout_p = DROPOUT_P, bidirectional = bi)\n",
    "        self.decoder = DecoderLSTM(embedding_tgt, h_dim, num_layers * 2 if bi else num_layers, dropout_p = DROPOUT_P)\n",
    "        self.attention = Attention(pad_token = self.pad_token, bidirectional = bi, h_dim = self.h_dim)\n",
    "\n",
    "        # Create linear layers to combine context and hidden state\n",
    "        self.linear1 = nn.Linear(2 * self.h_dim, self.emb_dim_tgt)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.dropout = nn.Dropout(DROPOUT_P)\n",
    "        self.linear2 = nn.Linear(self.emb_dim_tgt, self.vocab_size_tgt)\n",
    "        \n",
    "        # Share weights between decoder embedding and output \n",
    "        if self.decoder.embedding.weight.size() == self.linear2.weight.size():\n",
    "            self.linear2.weight = self.decoder.embedding.weight\n",
    "\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        if use_gpu: src = src.cuda()\n",
    "        \n",
    "        # Encode\n",
    "        out_e, final_e = self.encoder(src)\n",
    "        \n",
    "        # Decode\n",
    "        out_d, final_d = self.decoder(tgt, final_e)\n",
    "        \n",
    "        # Attend\n",
    "        context = self.attention(src, out_e, out_d)\n",
    "        out_cat = torch.cat((out_d, context), dim = 2) \n",
    "        \n",
    "        # Predict (returns probabilities)\n",
    "        x = self.linear1(out_cat)\n",
    "        x = self.dropout(self.tanh(x))\n",
    "        x = self.linear2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "    def predict(self, src): \n",
    "        '''\n",
    "        Predict top 1 sentence using beam search.\n",
    "        '''\n",
    "        beam_outputs = self.beam_search(src, max_len = 30) # returns top beam_size options (as list of tuples)\n",
    "        top1 = beam_outputs[0][1] # a list of word indices (as ints)\n",
    "        \n",
    "        return top1\n",
    "\n",
    "\n",
    "    def beam_search(self, src, max_len, remove_tokens = []):\n",
    "        '''\n",
    "        Returns top beam_size sentences using beam search.\n",
    "        '''\n",
    "        if use_gpu: src = src.cuda()\n",
    "        \n",
    "        # Encode\n",
    "        outputs_e, states = self.encoder(src)\n",
    "        \n",
    "        # Start with '<s>'\n",
    "        init_sent = [self.bos_token]\n",
    "        best_options = [(INIT_LPROB, init_sent, states)]\n",
    "        \n",
    "        # Beam search\n",
    "        # Store best k options\n",
    "        k = BEAM_SIZE \n",
    "\n",
    "        for length in range(max_len): # maximum target length\n",
    "\n",
    "            options = [] # candidates \n",
    "\n",
    "            for lprob, sentence, current_state in best_options:\n",
    "\n",
    "                # Prepare last word\n",
    "                last_word = sentence[-1]\n",
    "\n",
    "                if last_word != self.eos_token:\n",
    "                    last_word_input = torch.LongTensor([last_word]).view(1, 1)\n",
    "\n",
    "                    if use_gpu: last_word_input = last_word_input.cuda()\n",
    "\n",
    "                    # Decode\n",
    "                    outputs_d, new_state = self.decoder(last_word_input, current_state)\n",
    "                    \n",
    "                    # Attend\n",
    "                    context = self.attention(src, outputs_e, outputs_d)\n",
    "                    \n",
    "                    out_cat = torch.cat((outputs_d, context), dim=2)\n",
    "                    \n",
    "                    x = self.linear1(out_cat)\n",
    "                    x = self.dropout(self.tanh(x))\n",
    "                    x = self.linear2(x)\n",
    "                    x = x.squeeze().data.clone()\n",
    "                    \n",
    "                    # Block predictions of tokens in remove_tokens\n",
    "                    for t in remove_tokens: x[t] = -10e10\n",
    "                    \n",
    "                    lprobs = torch.log(x.exp() / x.exp().sum()) # log softmax\n",
    "                    \n",
    "                    # Add top k candidates to options list for next word\n",
    "                    for index in torch.topk(lprobs, k)[1]: \n",
    "                        option = (float(lprobs[index]) + lprob, sentence + [index], new_state) \n",
    "                        options.append(option)\n",
    "                \n",
    "                else: # keep sentences ending in '</s>' as candidates\n",
    "                    options.append((lprob, sentence, current_state))\n",
    "            \n",
    "            options.sort(key = lambda x: x[0], reverse = True) # sort by lprob\n",
    "            best_options = options[:k] # place top candidates in beam\n",
    "        \n",
    "        best_options.sort(key = lambda x: x[0], reverse = True)\n",
    "        \n",
    "        return best_options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criamos uma classe para facilitar o cálculo da média móvel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "  '''\n",
    "  A handy class for moving averages\n",
    "  ''' \n",
    "  def __init__(self):\n",
    "    self.reset()\n",
    "  \n",
    "  \n",
    "  def reset(self):\n",
    "    self.val, self.avg, self.sum, self.count = 0, 0, 0, 0\n",
    "  \n",
    "  def update(self, val, n=1):\n",
    "    self.val = val\n",
    "    self.sum += val * n\n",
    "    self.count += n\n",
    "    self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na célula abaixaos calculamos a [pontuação BLEU (BLEU score)](https://machinelearningmastery.com/calculate-bleu-score-for-text-python/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bleu(val_iter, model, criterion, SRC, TGT):\n",
    "    model.eval()\n",
    "  \n",
    "    # Iterate over words in validation batch. \n",
    "    bleu = AverageMeter()\n",
    "\n",
    "    sents_out = [] # list of sentences from decoder\n",
    "    sents_ref = [] # list of target sentences \n",
    "\n",
    "    for i, batch in enumerate(val_iter):\n",
    "        # Use GPU\n",
    "        src = batch.src.cuda() if use_gpu else batch.src\n",
    "        trg = batch.trg.cuda() if use_gpu else batch.trg\n",
    "\n",
    "        # Get model prediction (from beam search)\n",
    "        out = model.predict(src) # list of ints (word indices)\n",
    "        ref = list(trg.data.squeeze())\n",
    "\n",
    "        # Prepare sentence for bleu calculus\n",
    "        remove_tokens = [TGT.vocab.stoi['<pad>'], TGT.vocab.stoi['<s>'], TGT.vocab.stoi['</s>']] \n",
    "        \n",
    "        out = [w for w in out if w not in remove_tokens]\n",
    "        ref = [w for w in ref if w not in remove_tokens]\n",
    "        \n",
    "        sent_out = ' '.join(TGT.vocab.itos[j] for j in out)\n",
    "        sent_ref = ' '.join(TGT.vocab.itos[j] for j in ref)\n",
    "        \n",
    "        sents_out.append(sent_out)\n",
    "        sents_ref.append(sent_ref)\n",
    "    \n",
    "    # Run moses corpus bleu calculation \n",
    "    bleu = corpus_bleu(sents_out, sents_ref) \n",
    "    \n",
    "    return bleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante o treinamento, simplesmente calculamos a probabilidade logarítmica da sentença verdadeira no nosso modelo. A exponencial desse valor é conhecida como [perplexidade](https://en.wikipedia.org/wiki/Perplexity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_losses(val_iter, model, criterion):\n",
    "    '''\n",
    "    Calculate losses by teacher forcing on the validation set\n",
    "    '''\n",
    "    model.eval()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    for i, batch in enumerate(val_iter):\n",
    "        src = batch.src.cuda() if use_gpu else batch.src\n",
    "        tgt = batch.trg.cuda() if use_gpu else batch.trg\n",
    "        \n",
    "        # Forward \n",
    "        scores = model(src, tgt)\n",
    "        scores = scores[:-1]\n",
    "        tgt = tgt[1:]           \n",
    "        \n",
    "        # Reshape for loss function\n",
    "        scores = scores.view(scores.size(0) * scores.size(1), scores.size(2))\n",
    "        tgt = tgt.view(scores.size(0))\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(scores, tgt) \n",
    "        losses.update(loss.item())\n",
    "    \n",
    "    return losses.avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cada iteração de treinamento, atualizamos nossos pesos de modelo com gradiente descendente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_iter, val_iter, model, criterion, optimizer):  \n",
    "\n",
    "    bleu_best = -1\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "\n",
    "        # Validade model with BLEU\n",
    "        bleu_val = calculate_bleu(val_iter, model, criterion, SRC, TGT)\n",
    "        print(\"BLEU: \" + str(bleu_val))\n",
    "\n",
    "        if bleu_val > bleu_best:\n",
    "            bleu_best = bleu_val\n",
    "            repeat = 0\n",
    "\n",
    "            print('Saving best model...')\n",
    "            torch.save(model, write_path)\n",
    "        else:\n",
    "            repeat += 1\n",
    "\n",
    "        if repeat == EARLY_STOP:\n",
    "            break\n",
    "      \n",
    "        # Validate model\n",
    "        with torch.no_grad():\n",
    "            val_loss = validate_losses(val_iter, model, criterion) \n",
    "            print('Validating Epoch [{e}/{num_e}]\\t Average loss: {l:.3f}\\t Perplexity: {p:.3f}'.format(\n",
    "                e = epoch, num_e = NUM_EPOCHS, l = val_loss, p = torch.FloatTensor([val_loss]).exp().item())\n",
    "            )\n",
    "\n",
    "        # Train model\n",
    "        model.train()\n",
    "\n",
    "        losses = AverageMeter()\n",
    "\n",
    "        for i, batch in enumerate(train_iter): \n",
    "            src = batch.src.cuda() if use_gpu else batch.src\n",
    "            tgt = batch.trg.cuda() if use_gpu else batch.trg\n",
    "            \n",
    "            # Forward, backprop, optimizer\n",
    "            model.zero_grad()\n",
    "            scores = model(src, tgt)\n",
    "\n",
    "            # Remove <s> from target and </s> from scores (output)\n",
    "            scores = scores[:-1]\n",
    "            tgt = tgt[1:]           \n",
    "\n",
    "            # Reshape for loss function\n",
    "            scores = scores.view(scores.size(0) * scores.size(1), scores.size(2))\n",
    "            tgt = tgt.view(scores.size(0))\n",
    "\n",
    "            # Pass through loss function\n",
    "            loss = criterion(scores, tgt) \n",
    "            loss.backward()\n",
    "            losses.update(loss.item())\n",
    "\n",
    "            # Clip gradient norms and step optimizer\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Log within epoch\n",
    "            if i % 1000 == 0:\n",
    "                print('''Epoch [{e}/{num_e}]\\t Batch [{b}/{num_b}]\\t Loss: {l:.3f}'''.format(\n",
    "                    e = epoch + 1, num_e = NUM_EPOCHS, b = i, num_b = len(train_iter), l = losses.avg)\n",
    "                )\n",
    "\n",
    "        # Log after each epoch\n",
    "        print('''Epoch [{e}/{num_e}] complete. Loss: {l:.3f}'''.format(\n",
    "            e = epoch + 1, num_e = NUM_EPOCHS, l = losses.avg)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, precisamos de uma função de previsão real para ver nossas traduções!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_from_text(model, input_sentence, SRC, TGT):\n",
    "    sent_german = input_sentence.split(' ') # sentence --> list of words\n",
    "    sent_indices = [SRC.vocab.stoi[word] if word in SRC.vocab.stoi else SRC.vocab.stoi['<unk>'] for word in sent_german]\n",
    "    sent = torch.LongTensor([sent_indices])\n",
    "    \n",
    "    if use_gpu: sent = sent.cuda()\n",
    "    \n",
    "    sent = sent.view(-1,1) # reshape to sl x bs\n",
    "    \n",
    "    print('German: ' + ' '.join([SRC.vocab.itos[index] for index in sent_indices]))\n",
    "    \n",
    "    # Predict five sentences with beam search \n",
    "    pred = model.predict(sent)\n",
    "    out = ' '.join([TGT.vocab.itos[index] for index in pred[1:-1]])\n",
    "    \n",
    "    print('English: ' + out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tradução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente, carregamos nossos embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_embeddings(np_src_file, np_tgt_file):\n",
    "    '''\n",
    "    Load English and German embeddings from saved numpy files\n",
    "    '''\n",
    "    emb_tr_src = torch.from_numpy(np.load(np_src_file))\n",
    "    emb_tr_tgt = torch.from_numpy(np.load(np_tgt_file))\n",
    "    \n",
    "    return emb_tr_src, emb_tr_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_src, embedding_tgt = download_embeddings('emb-3327-de.npy', 'emb-3124-en.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, criamos nosso modelo e o movemos para a GPU (caso disponível)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model \n",
    "tokens = [TGT.vocab.stoi[x] for x in ['<s>', '</s>', '<pad>', '<unk>']]\n",
    "model = Seq2seq(embedding_src, embedding_tgt, 300, 2, 0.3, True, tokens_bos_eos_pad_unk=tokens)\n",
    "model = model.cuda() if use_gpu else model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida, fazemos nossa função de perda de entropia cruzada (criterion) e otimizador. Para nosso otimizador, usaremos Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create weight to mask padding tokens for loss function\n",
    "weight = torch.ones(len(TGT.vocab))\n",
    "weight[TGT.vocab.stoi['<pad>']] = 0\n",
    "weight = weight.cuda() if use_gpu else weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss(weight = weight)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, podemos treinar nosso modelo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU: 9.889732042449922e-232\n",
      "Saving best model...\n",
      "Validating Epoch [0/10]\t Average loss: 8.059\t Perplexity: 3160.866\n",
      "Epoch [1/10]\t Batch [0/1690]\t Loss: 8.053\n",
      "Epoch [1/10]\t Batch [1000/1690]\t Loss: 2.836\n",
      "Epoch [1/10] complete. Loss: 2.454\n",
      "BLEU: 1.3590428432786202e-231\n",
      "Saving best model...\n",
      "Validating Epoch [1/10]\t Average loss: 1.683\t Perplexity: 5.383\n",
      "Epoch [2/10]\t Batch [0/1690]\t Loss: 1.457\n",
      "Epoch [2/10]\t Batch [1000/1690]\t Loss: 1.590\n",
      "Epoch [2/10] complete. Loss: 1.574\n",
      "BLEU: 1.3639056088789068e-231\n",
      "Saving best model...\n",
      "Validating Epoch [2/10]\t Average loss: 1.504\t Perplexity: 4.501\n",
      "Epoch [3/10]\t Batch [0/1690]\t Loss: 1.055\n",
      "Epoch [3/10]\t Batch [1000/1690]\t Loss: 1.316\n",
      "Epoch [3/10] complete. Loss: 1.328\n",
      "BLEU: 1.3638470951777366e-231\n",
      "Validating Epoch [3/10]\t Average loss: 1.482\t Perplexity: 4.400\n",
      "Epoch [4/10]\t Batch [0/1690]\t Loss: 1.266\n",
      "Epoch [4/10]\t Batch [1000/1690]\t Loss: 1.114\n",
      "Epoch [4/10] complete. Loss: 1.140\n",
      "BLEU: 1.365210457060724e-231\n",
      "Saving best model...\n",
      "Validating Epoch [4/10]\t Average loss: 1.511\t Perplexity: 4.531\n",
      "Epoch [5/10]\t Batch [0/1690]\t Loss: 0.835\n",
      "Epoch [5/10]\t Batch [1000/1690]\t Loss: 0.931\n",
      "Epoch [5/10] complete. Loss: 0.962\n",
      "BLEU: 1.3640811048112915e-231\n",
      "Validating Epoch [5/10]\t Average loss: 1.613\t Perplexity: 5.019\n",
      "Epoch [6/10]\t Batch [0/1690]\t Loss: 0.818\n",
      "Epoch [6/10]\t Batch [1000/1690]\t Loss: 0.760\n",
      "Epoch [6/10] complete. Loss: 0.802\n",
      "BLEU: 1.3680796209868423e-231\n",
      "Saving best model...\n",
      "Validating Epoch [6/10]\t Average loss: 1.718\t Perplexity: 5.572\n",
      "Epoch [7/10]\t Batch [0/1690]\t Loss: 0.627\n",
      "Epoch [7/10]\t Batch [1000/1690]\t Loss: 0.620\n",
      "Epoch [7/10] complete. Loss: 0.664\n",
      "BLEU: 1.3653076838859614e-231\n",
      "Validating Epoch [7/10]\t Average loss: 1.818\t Perplexity: 6.161\n",
      "Epoch [8/10]\t Batch [0/1690]\t Loss: 0.421\n",
      "Epoch [8/10]\t Batch [1000/1690]\t Loss: 0.513\n",
      "Epoch [8/10] complete. Loss: 0.559\n",
      "BLEU: 1.3647824120574365e-231\n",
      "Validating Epoch [8/10]\t Average loss: 1.945\t Perplexity: 6.997\n",
      "Epoch [9/10]\t Batch [0/1690]\t Loss: 0.454\n",
      "Epoch [9/10]\t Batch [1000/1690]\t Loss: 0.424\n",
      "Epoch [9/10] complete. Loss: 0.469\n",
      "BLEU: 1.3656769565162228e-231\n",
      "Validating Epoch [9/10]\t Average loss: 2.053\t Perplexity: 7.794\n",
      "Epoch [10/10]\t Batch [0/1690]\t Loss: 0.358\n",
      "Epoch [10/10]\t Batch [1000/1690]\t Loss: 0.376\n",
      "Epoch [10/10] complete. Loss: 0.414\n"
     ]
    }
   ],
   "source": [
    "train(train_iter, val_iter, model, criterion, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, podemos traduzir algumas frases em alemão! Vamos tentar alguns do jornal alemão Süddeutsche Zeitung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German: Ich <unk> nur <unk> ich <unk> in den Bergen und ich <unk> die Berge .\n",
      "English: I got more I children got <unk> in the mountains , I I 's mountains .\n"
     ]
    }
   ],
   "source": [
    "input = \"Ich kenne nur Berge, ich bleibe in den Bergen und ich liebe die Berge .\"\n",
    "predict_from_text(model, input, SRC, TGT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "German: <unk> <unk> <unk> sich als <unk> als <unk> .\n",
      "English: <unk> <unk> <unk> than <unk> <unk> than <unk> as <unk> <unk> .\n"
     ]
    }
   ],
   "source": [
    "input = \"Ihre Bergung erwies sich als komplizierter als gedacht .\" \n",
    "predict_from_text(model, input, SRC, TGT)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
